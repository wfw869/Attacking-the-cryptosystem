import numpy as np
import paddle as paddle
import paddle.dataset.mnist as mnist
import paddle.fluid as fluid
from PIL import Image
import matplotlib.pyplot as plt
from multiprocessing import cpu_count
import cv2 as cv
import os
import time
import gzip
import sys
import pickle

def load_mnist(path, kind='train'):
    labels_path = os.path.join(path,
                               '%s-labels-idx1-ubyte.gz'% kind)
    images_path = os.path.join(path,
                               '%s-images-idx3-ubyte.gz'% kind)

    with gzip.open(labels_path, 'rb') as lbpath:
        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)

    with gzip.open(images_path, 'rb') as imgpath:
        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)
    return images, labels
    
def data_mapper(sample):
    img, label = sample
    
    img= img.flatten().astype('float32')/255.0
    return img, label
    
# reader
def data_train(file_list,mode, buffered_size=0):
    def reader():
        images, labels=load_mnist(file_list,mode)
        for i in range(4800):
            yield images[i],labels[i]
    
    return paddle.reader.xmap_readers(data_mapper, reader,cpu_count(), buffered_size)
def data_test(file_list,mode, buffered_size=0):
    def reader():
        images, labels=load_mnist(file_list,mode)
        for i in range(200):
            yield images[i],labels[i]
    
    return paddle.reader.xmap_readers(data_mapper, reader,cpu_count(), buffered_size)

    

def reader_createor(data, label):
    def reader():
        for i in  range(len(data)):
            yield data[i,:], int(label[i])
    return reader

#preprocessing
def change_1(x): #standardized
    y=(x-np.min(x))/(np.max(x)-np.min(x)) 
    return (y-0.5)/0.5

def change_tensor_1(x): 
    y=(x-fluid.layers.reduce_min(x,dim=[1,2,3],keep_dim=True))/(fluid.layers.reduce_max(x,dim=[1,2,3],keep_dim=True)-fluid.layers.reduce_min(x,dim=[1,2,3],keep_dim=True))
    return (y-0.5)/0.5

def change1(x): #0-1
    y=(x-np.min(x))/(np.max(x)-np.min(x)) 
    return y
def change_tensor1(x): 
    y=(x-fluid.layers.reduce_min(x,dim=[1,2,3],keep_dim=True))/(fluid.layers.reduce_max(x,dim=[1,2,3],keep_dim=True)-fluid.layers.reduce_min(x,dim=[1,2,3],keep_dim=True))
    return y

def cc(y,x):
    x1=fluid.layers.reduce_mean(x,dim=[1,2,3],keep_dim=True)
    y1=fluid.layers.reduce_mean(y,dim=[1,2,3],keep_dim=True)
    CC1=fluid.layers.reduce_sum(fluid.layers.elementwise_mul((x-x1),(y-y1)),dim=[1,2,3])
    CC1=fluid.layers.reduce_mean(CC1)
    CC2=fluid.layers.sqrt((fluid.layers.reduce_sum(fluid.layers.square(x-x1),dim=[1,2,3]))*(fluid.layers.reduce_sum(fluid.layers.square(y-y1),dim=[1,2,3])))
    CC2=fluid.layers.reduce_mean(CC2)
    
    return CC1/CC2

def SSIM(y,x):
    x=change_tensor1(x)
    y=change_tensor1(y)
    x1=fluid.layers.reduce_mean(x,dim=[1,2,3],keep_dim=True)
    y1=fluid.layers.reduce_mean(y,dim=[1,2,3],keep_dim=True)
    t1=fluid.layers.reduce_mean(fluid.layers.elementwise_mul((x-x1),(x-x1)),dim=[1,2,3])
    t2=fluid.layers.reduce_mean(fluid.layers.elementwise_mul((y-y1),(y-y1)),dim=[1,2,3])
    t12=fluid.layers.reduce_mean(fluid.layers.elementwise_mul((x-x1),(y-y1)),dim=[1,2,3])
    CC1=(2*x1*y1+0.01*0.01)*(2*t12+0.03*0.03)
    CC2=(x1*x1+y1*y1+0.01*0.01)*(t1+t2+0.03*0.03)
    ssim=fluid.layers.mean(CC1/CC2)
    
    return ssim


def interference_change1(img):     
    # Fresnel diffraction
    z0 = 25  # diffractionmm  
    z1 = 50
    z2 = 75
    h = 633e-6  # wavelengthmm
    k = 2 * np.pi / h  # k
    N = 100
    dfx=5.3e-6
    dfy=5.3e-6
    fx,fy=np.meshgrid(np.linspace(-1/dfx/2, 1/dfy/2, N),np.linspace(-1/dfx/2, 1/dfy/2, N))
    U0 = change1(img)  
    H=np.exp(1j*k*z1*(1-h*h/2*(fx*fx+fy*fy)))
    H1=np.exp(1j*k*z0*(1-h*h/2*(fx*fx+fy*fy)))
    H2=np.exp(1j*k*z2*(1-h*h/2*(fx*fx+fy*fy)))
    # encryption
    np.random.seed(1)
    RPM1 = np.random.rand(N, N)  
    R1 =  np.exp(2j * np.pi*RPM1 )  
    np.random.seed(2)
    RPM2 = np.random.rand(N, N)  
    R2 = np.exp(2j * np.pi*RPM2 )
    np.random.seed(3)
    RPM3 = np.random.rand(N, N)  
    R3 = 1 * np.exp(2j * np.pi*RPM3 )
    np.random.seed(4)
    RPM4 = np.random.rand(N, N)  
    R4 = 1 * np.exp(2j * np.pi*RPM4 )
    np.random.seed(5)
    RPM5 = np.random.rand(N, N)  
    R5 = 1 * np.exp(2j * np.pi*RPM5 )
    u2 = U0  

    # u3 = np.fft.fftshift(np.fft.fft2(u2*fresne0))*pha0   
    u3 = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(np.fft.fft2(u2))*H))  
    u4 = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(np.fft.fft2(u3*R1))*H))
    u5 = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(np.fft.fft2(u4*R2))*H))
    r3 = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(np.fft.fft2(R3))*H))  
    r4 = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(np.fft.fft2(r3*R4))*H2))
    r5 = np.fft.ifftshift(np.fft.ifft2(np.fft.fftshift(np.fft.fft2(r3*R5))*H1))

    out = (abs(u5+r5))**2 #(u3+r3)*np.conjugate(u3+r3)
    return change1(out)
def val(x,N):
    x1=change1(x)
    for i in range(N):
        for j in range(N):
            if x1[i,j] > 0:
                x1[i,j]=1.0
    return x1


def EMD(data):
    x1=np.array(data)
    #x6=np.zeros([50,2],dtype=np.float32)
    x6=[]
    for i in range(0,10):
        l=[]
        x2=np.reshape(x1[i,0],(28,28))
        x3=cv.resize(x2, (100, 100), interpolation=cv.INTER_LINEAR)
        #x3=change_1(x3)
        #x=cv.resize(x2, (100, 100), interpolation=cv.INTER_LINEAR)
        x=np.reshape(change1(x2),(28*28))
        x4=interference_change1(x3)
        #x5=cv.resize(x4, (100, 100), interpolation=cv.INTER_LINEAR)
        x5=np.reshape(change1(x4),(100*100))
        l.append((x,x5))
        x6.append(l)
    return np.squeeze(x6).tolist()

trainer_reader = data_train(file_list="datasets/data7688/",mode="train")
train_reader = paddle.batch(paddle.reader.shuffle(reader=trainer_reader,buf_size=500),batch_size=10)
tester_reader = data_test(file_list="datasets/data7688/",mode="t10k")
test_reader = paddle.batch(paddle.reader.shuffle(reader=tester_reader,buf_size=100),batch_size=10)

def network(x):
    x1=fluid.layers.conv2d(x,num_filters=20,filter_size=5,stride=1,padding=0,act="sigmoid")
    pool_1=fluid.layers.pool2d(x1,pool_size=2,pool_type="max",pool_stride=2,pool_padding="SAME")
    x2=fluid.layers.conv2d(pool_1,num_filters=20,filter_size=5,stride=1,padding=0,act="sigmoid")
    pool_2=fluid.layers.pool2d(x2,pool_size=2,pool_type="max",pool_stride=2,pool_padding="SAME")
    x3=fluid.layers.reshape(pool_2,[-1,1,1,9680])
    x4=fluid.layers.fc(x3,784)
    x5=fluid.layers.reshape(x4,[-1,1,28,28])
    return x5

with fluid.unique_name.guard():
    #Input
    data_shape = [1, 28, 28]
    output = fluid.layers.data(name='output', shape=data_shape, dtype='float32')#original
    images = fluid.layers.data(name='images', shape=[1,100,100], dtype='float32')
    predict = change_tensor1(network(images))
    cost = fluid.layers.reduce_mean(fluid.layers.square(predict - output),dim=[1,2,3])
    avg_cost = fluid.layers.mean(cost)                            
    acc = cc(predict, output)      
    optimizer =fluid.optimizer.Adam(learning_rate=0.001)#,regularization=fluid.regularizer.L2Decay(regularization_coeff=0.0005)
    optimizer.minimize(avg_cost)#parameter_list=['conv1_w', 'conv2_w','conv3_w','conv4_w','conv5_w','conv6_w','conv12_w'])
test_program = fluid.Program()
with fluid.unique_name.guard():
    with fluid.program_guard(test_program, fluid.Program()):
        data_shape = [1, 28, 28]
        output = fluid.layers.data(name='output', shape=data_shape, dtype='float32')
        images = fluid.layers.data(name='images', shape=[1,100,100], dtype='float32')
        predict = change_tensor1(network(images))
        cost1 = fluid.layers.reduce_mean(fluid.layers.square(predict - output),dim=[1,2,3])
        avg_cost1 = fluid.layers.mean(cost1)                            
        acc1 = cc(predict, output)
        ssim = SSIM(predict, output)

# GPU>use_cuda = True
use_cuda = True
place = fluid.CUDAPlace(0) if use_cuda else fluid.CPUPlace()

# initialize
exe = fluid.Executor(place)
exe.run(fluid.default_startup_program())
#DataFeeder 
feeder = fluid.DataFeeder( feed_list=[output,images],place=place)

EPOCH_NUM = 20
model_save_dir = "work/C1002.inference.model"
start_time=time.time()
for pass_id in range(EPOCH_NUM):
    # Train
    for batch_id, data in enumerate(train_reader()):
        x=EMD(data)
        train_cost,train_acc = exe.run(program=fluid.default_main_program(),           
                            feed=feeder.feed(x),                        
                            fetch_list=[avg_cost, acc])                    

        
        if batch_id % 200 == 0:                                             
            print('Pass:%d, Batch:%d, Cost:%0.5f, Accuracy:%0.5f' %(pass_id, batch_id, train_cost[0], train_acc[0])) 
    
    # validation
    test_costs = []                                                         
    test_accs = []                                                         
    test_ssims=[]
    for batch_id, data in enumerate(test_reader()):
        if batch_id < 100:
            x1=EMD(data)
            test_cost, test_acc,test_ssim = exe.run(program=test_program,                 
                                        feed=feeder.feed(x1),              
                                        fetch_list=[avg_cost1, acc1, ssim])           
            test_costs.append(np.mean(test_cost))                                     
            test_accs.append(np.mean(test_acc))                                       
            test_ssims.append(np.mean(test_ssim))
   
    test_cost2 = (sum(test_costs) / len(test_costs))                         
    test_acc2 = (sum(test_accs) / len(test_accs))                            
    test_ssim2= (sum(test_ssims) / len(test_ssims)) 
    print('Test:%d, Cost:%0.5f, ACC:%0.5f, SSIM:%0.5f' % (pass_id, test_cost2, test_acc2,test_ssim2))
end_time=time.time()
tepoch_time=end_time-start_time
print('time:' + str(tepoch_time))

#save model

if not os.path.exists(model_save_dir):
    os.makedirs(model_save_dir)
print ('save models to %s' % (model_save_dir))
fluid.io.save_inference_model(model_save_dir,['images'],[predict],exe)


print('Finish！')
